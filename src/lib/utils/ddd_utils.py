# ------------------------------------------------------------------------------
# Licensed under the MIT License.
# Written by Xingyi Zhou (zhouxy@cs.utexas.edu)
# Source: https://github.com/xingyizhou/CenterTrack/blob/master/src/lib/utils/ddd_utils.py
# Modified by Mohamed Chaabane
# ------------------------------------------------------------------------------


from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import numpy as np
import cv2
from lib.utils.matching import convert_3dbox_to_8corner


def comput_corners_3d(dim, rotation_y):
    # dim: 3
    # location: 3
    # rotation_y: 1
    # return: 8 x 3
    c, s = np.cos(rotation_y), np.sin(rotation_y)
    R = np.array([[c, 0, s], [0, 1, 0], [-s, 0, c]], dtype=np.float32)
    l, w, h = dim[2], dim[1], dim[0]
    x_corners = [l / 2, l / 2, -l / 2, -l / 2, l / 2, l / 2, -l / 2, -l / 2]
    y_corners = [0, 0, 0, 0, -h, -h, -h, -h]
    z_corners = [w / 2, -w / 2, -w / 2, w / 2, w / 2, -w / 2, -w / 2, w / 2]

    corners = np.array([x_corners, y_corners, z_corners], dtype=np.float32)
    corners_3d = np.dot(R, corners).transpose(1, 0)
    return corners_3d


def compute_box_3d(dim, location, rotation_y):
    # dim: 3
    # location: 3
    # rotation_y: 1
    # return: 8 x 3
    corners_3d = comput_corners_3d(dim, rotation_y)
    corners_3d = corners_3d + np.array(location, dtype=np.float32).reshape(1, 3)
    return corners_3d


def project_to_image(pts_3d, P):
    # pts_3d: n x 3
    # P: 3 x 4
    # return: n x 2
    pts_3d_homo = np.concatenate(
        [pts_3d, np.ones((pts_3d.shape[0], 1), dtype=np.float32)], axis=1
    )
    pts_2d = np.dot(P, pts_3d_homo.transpose(1, 0)).transpose(1, 0)
    pts_2d = pts_2d[:, :2] / pts_2d[:, 2:]
    # import pdb; pdb.set_trace()
    return pts_2d


def compute_orientation_3d(dim, location, rotation_y):
    # dim: 3
    # location: 3
    # rotation_y: 1
    # return: 2 x 3
    c, s = np.cos(rotation_y), np.sin(rotation_y)
    R = np.array([[c, 0, s], [0, 1, 0], [-s, 0, c]], dtype=np.float32)
    orientation_3d = np.array([[0, dim[2]], [0, 0], [0, 0]], dtype=np.float32)
    orientation_3d = np.dot(R, orientation_3d)
    orientation_3d = orientation_3d + np.array(location, dtype=np.float32).reshape(3, 1)
    return orientation_3d.transpose(1, 0)


def draw_box_3d(image, corners, c=(255, 0, 255), same_color=False):
    face_idx = [[0, 1, 5, 4], [1, 2, 6, 5], [3, 0, 4, 7], [2, 3, 7, 6]]
    right_corners = [1, 2, 6, 5] if not same_color else []
    left_corners = [0, 3, 7, 4] if not same_color else []
    thickness = 4 if same_color else 2
    corners = corners.astype(np.int32)
    for ind_f in range(3, -1, -1):
        f = face_idx[ind_f]
        for j in range(4):
            cc = c
            if (f[j] in left_corners) and (f[(j + 1) % 4] in left_corners):
                cc = (255, 0, 0)
            if (f[j] in right_corners) and (f[(j + 1) % 4] in right_corners):
                cc = (0, 0, 255)
            try:
                cv2.line(
                    image,
                    (corners[f[j], 0], corners[f[j], 1]),
                    (corners[f[(j + 1) % 4], 0], corners[f[(j + 1) % 4], 1]),
                    cc,
                    thickness,
                    lineType=cv2.LINE_AA,
                )
            except Exception as e:
                print(e)
        if ind_f == 0:
            try:
                cv2.line(
                    image,
                    (corners[f[0], 0], corners[f[0], 1]),
                    (corners[f[2], 0], corners[f[2], 1]),
                    c,
                    1,
                    lineType=cv2.LINE_AA,
                )
                cv2.line(
                    image,
                    (corners[f[1], 0], corners[f[1], 1]),
                    (corners[f[3], 0], corners[f[3], 1]),
                    c,
                    1,
                    lineType=cv2.LINE_AA,
                )
            except Exception as e:
                print(e)
        # top_idx = [0, 1, 2, 3]
    return image

def unproject(points, Z, intrinsic, distortion):
  f_x = intrinsic[0, 0]
  f_y = intrinsic[1, 1]
  c_x = intrinsic[0, 2]
  c_y = intrinsic[1, 2]
  # This was an error before
  # c_x = intrinsic[0, 3]
  # c_y = intrinsic[1, 3]

  # Step 1. Undistort.
  points_undistorted = np.array([])
  if len(points) > 0:
    points_undistorted = cv2.undistortPoints(np.expand_dims(points, axis=1), intrinsic, distortion, P=intrinsic)
  points_undistorted = np.squeeze(points_undistorted, axis=1)

  # Step 2. Reproject.
  result = []
  for idx in range(points_undistorted.shape[0]):
    z = Z[0] if len(Z) == 1 else Z[idx]
    x = (points_undistorted[idx, 0] - c_x) / f_x * z
    y = (points_undistorted[idx, 1] - c_y) / f_y * z
    result.append([x, y, z])
  return result


def unproject_2d_to_3d(pt_2d, depth, P):
    # pts_2d: 2
    # depth: 1
    # P: 3 x 4
    # return: 3
    z = depth - P[2, 3]
    x = (pt_2d[0] * depth - P[0, 3] - P[0, 2] * z) / P[0, 0]
    y = (pt_2d[1] * depth - P[1, 3] - P[1, 2] * z) / P[1, 1]
    pt_3d = np.array([x, y, z], dtype=np.float32).reshape(3)
    return pt_3d

# ex calib nuscene
# "calib": [[1266.417236328125, 0.0, 816.2670288085938, 0.0],
#           [0.0, 1266.417236328125, 491.507080078125, 0.0],
#           [0.0, 0.0, 1.0, 0.0]]


def alpha2rot_y(alpha, x, cx, fx):
    """
    Get rotation_y by alpha + theta - 180
    alpha : Observation angle of object, ranging [-pi..pi]
    x : Object center x to the camera center (x-W/2), in pixels
    rotation_y : Rotation ry around Y-axis in camera coordinates [-pi..pi]
    """
    rot_y = alpha + np.arctan2(x - cx, fx)
    if rot_y > np.pi:
        rot_y -= 2 * np.pi
    if rot_y < -np.pi:
        rot_y += 2 * np.pi
    return rot_y


def rot_y2alpha(rot_y, x, cx, fx):
    """
    Get rotation_y by alpha + theta - 180
    alpha : Observation angle of object, ranging [-pi..pi]
    x : Object center x to the camera center (x-W/2), in pixels
    rotation_y : Rotation ry around Y-axis in camera coordinates [-pi..pi]
    """
    alpha = rot_y - np.arctan2(x - cx, fx)
    if alpha > np.pi:
        alpha -= 2 * np.pi
    if alpha < -np.pi:
        alpha += 2 * np.pi
    return alpha


def ddd2locrot(center, alpha, dim, depth, calib, dist_coeff=None):
    # single image
    if dist_coeff is None:
        locations = unproject_2d_to_3d(center, depth, calib)
    if dist_coeff is not None:
        locations = np.asarray(unproject(center, [depth], calib[:,:3], dist_coeff)[0]).squeeze()
    locations[1] += dim[0] / 2
    rotation_y = alpha2rot_y(alpha, center[0], calib[0, 2], calib[0, 0])
    return locations, rotation_y


def project_3d_bbox(location, dim, rotation_y, calib):
    box_3d = compute_box_3d(dim, location, rotation_y)
    box_2d = project_to_image(box_3d, calib)
    return box_2d


import torch

# Original author: Francisco Massa:
# https://github.com/fmassa/object-detection.torch
# Ported to PyTorch by Max deGroot (02/01/2017)
def nms(boxes, scores, overlap=0.93, top_k=200):
    """Apply non-maximum suppression at test time to avoid detecting too many
    overlapping bounding boxes for a given object.
    Args:
        boxes: (tensor) The location preds for the img, Shape: [num_priors,4].
        scores: (tensor) The class predscores for the img, Shape:[num_priors].
        overlap: (float) The overlap thresh for suppressing unnecessary boxes.
        top_k: (int) The Maximum number of box preds to consider.
    Return:
        The indices of the kept boxes with respect to num_priors.
    """

    keep = scores.new(scores.size(0)).zero_().long()
    if boxes.numel() == 0:
        return keep
    x1 = boxes[:, 0]
    y1 = boxes[:, 1]
    x2 = boxes[:, 2]
    y2 = boxes[:, 3]
    area = torch.mul(x2 - x1, y2 - y1)
    v, idx = scores.sort(0)  # sort in ascending order
    # I = I[v >= 0.01]
    idx = idx[-top_k:]  # indices of the top-k largest vals
    xx1 = boxes.new()
    yy1 = boxes.new()
    xx2 = boxes.new()
    yy2 = boxes.new()
    w = boxes.new()
    h = boxes.new()

    # keep = torch.Tensor()
    count = 0
    while idx.numel() > 0:
        i = idx[-1]  # index of current largest val
        # keep.append(i)
        keep[count] = i
        count += 1
        if idx.size(0) == 1:
            break
        idx = idx[:-1]  # remove kept element from view
        # load bboxes of next highest vals
        torch.index_select(x1, 0, idx, out=xx1)
        torch.index_select(y1, 0, idx, out=yy1)
        torch.index_select(x2, 0, idx, out=xx2)
        torch.index_select(y2, 0, idx, out=yy2)
        # store element-wise max with next highest score
        xx1 = torch.clamp(xx1, min=x1[i])
        yy1 = torch.clamp(yy1, min=y1[i])
        xx2 = torch.clamp(xx2, max=x2[i])
        yy2 = torch.clamp(yy2, max=y2[i])
        w.resize_as_(xx2)
        h.resize_as_(yy2)
        w = xx2 - xx1
        h = yy2 - yy1
        # check sizes of xx1 and xx2.. after each iteration
        w = torch.clamp(w, min=0.0)
        h = torch.clamp(h, min=0.0)
        inter = w * h
        # IoU = i / (area(a) + area(b) - i)
        rem_areas = torch.index_select(area, 0, idx)  # load remaining areas)
        union = (rem_areas - inter) + area[i]
        IoU = inter.float() / union.float()  # store result in iou
        # keep only elements with an IoU <= overlap
        idx = idx[IoU.le(overlap)]
    return keep, count

    return keep, count


if __name__ == "__main__":
    calib = np.array(
        [
            [
                7.070493000000e02,
                0.000000000000e00,
                6.040814000000e02,
                4.575831000000e01,
            ],
            [
                0.000000000000e00,
                7.070493000000e02,
                1.805066000000e02,
                -3.454157000000e-01,
            ],
            [
                0.000000000000e00,
                0.000000000000e00,
                1.000000000000e00,
                4.981016000000e-03,
            ],
        ],
        dtype=np.float32,
    )
    alpha = -0.20
    tl = np.array([712.40, 143.00], dtype=np.float32)
    br = np.array([810.73, 307.92], dtype=np.float32)
    ct = (tl + br) / 2
    rotation_y = 0.01
